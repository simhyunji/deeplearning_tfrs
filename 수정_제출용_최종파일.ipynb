{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11390,"status":"ok","timestamp":1709820478286,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"JT_BaPXbUqoA"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from matplotlib import font_manager, rc\n","from sklearn.preprocessing import LabelEncoder\n","import regex as re\n","import tensorflow as tf\n","import tensorflow_recommenders as tfrs\n","from typing import Dict, Text  # Dict 임포트 추가\n","font_path = \"C:/Windows/Fonts/malgun.ttf\"\n","# font = font_manager.FontProperties(fname = font_path).get_name()\n","# rc('font', family = font)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9353,"status":"ok","timestamp":1709820458108,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"My01dX4JcB9R","outputId":"12d6f389-c93a-4ca1-c406-d26d7a24c234"},"outputs":[],"source":["#pip install tensorflow_recommenders"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6352,"status":"ok","timestamp":1709820491463,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"UXpKDsA-UqoC"},"outputs":[{"data":{"text/plain":["(871393, 10)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train1 = pd.read_csv(\"train.csv\")\n","train=train1.copy()\n","train.shape"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1709820500668,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"D7PqylhQUqoC","outputId":"56eba730-4b36-4ba6-ac08-1efb0ef7f2e7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>User-ID</th>\n","      <th>Book-ID</th>\n","      <th>Book-Rating</th>\n","      <th>Age</th>\n","      <th>Location</th>\n","      <th>Book-Title</th>\n","      <th>Book-Author</th>\n","      <th>Year-Of-Publication</th>\n","      <th>Publisher</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_000000</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_044368</td>\n","      <td>8</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Road Taken</td>\n","      <td>Rona Jaffe</td>\n","      <td>2001.0</td>\n","      <td>Mira</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_000001</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_081205</td>\n","      <td>8</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Macbeth (New Penguin Shakespeare)</td>\n","      <td>William Shakespeare</td>\n","      <td>1981.0</td>\n","      <td>Penguin Books</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_000002</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_086781</td>\n","      <td>0</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Waverley (Penguin English Library)</td>\n","      <td>Walter Scott</td>\n","      <td>1981.0</td>\n","      <td>Penguin Books</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             ID     User-ID      Book-ID  Book-Rating   Age  \\\n","0  TRAIN_000000  USER_00000  BOOK_044368            8  23.0   \n","1  TRAIN_000001  USER_00000  BOOK_081205            8  23.0   \n","2  TRAIN_000002  USER_00000  BOOK_086781            0  23.0   \n","\n","                           Location                          Book-Title  \\\n","0  sackville, new brunswick, canada                          Road Taken   \n","1  sackville, new brunswick, canada   Macbeth (New Penguin Shakespeare)   \n","2  sackville, new brunswick, canada  Waverley (Penguin English Library)   \n","\n","           Book-Author  Year-Of-Publication      Publisher  \n","0           Rona Jaffe               2001.0           Mira  \n","1  William Shakespeare               1981.0  Penguin Books  \n","2         Walter Scott               1981.0  Penguin Books  "]},"metadata":{},"output_type":"display_data"}],"source":["display(train.head(3))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7792,"status":"ok","timestamp":1709825007182,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"sPVErk3Ycpou","outputId":"c718ddd7-32fd-40f8-bea9-5d2bb71d95fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["First 10 unique book titles: [' A Light in the Storm: The Civil War Diary of Amelia Martin, Fenwick Island, Delaware, 1861 (Dear America)', ' Always Have Popsicles', \" Apple Magic (The Collector's series)\", ' Ask Lily (Young Women of Faith: Lily Series, Book 5)', ' Beyond IBM: Leadership Marketing and Finance for the 1990s', ' Clifford Visita El Hospital (Clifford El Gran Perro Colorado)', ' Deceived', ' Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth', ' Final Fantasy Anthology: Official Strategy Guide (Brady Games)', ' Flight of Fancy: American Heiresses (Zebra Ballad Romance)']\n","Number of unique book titles: 217829\n","Number of unique user ids: 83256\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from typing import Dict, Text\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import StandardScaler\n","# 데이터 불러오기\n","train1 = pd.read_csv(\"train.csv\")\n","train_data=train1.copy()\n","# 필요한 열만 선택\n","train_data = train_data[[\"User-ID\", \"Book-Rating\", \"Book-Title\"]]\n","\n","\n","# TensorFlow 데이터셋으로 변환\n","ratings = tf.data.Dataset.from_tensor_slices({\n","        \"book_title\": train_data[\"Book-Title\"].values,\n","        \"user_id\": train_data[\"User-ID\"].values,\n","        \"book_rating\": train_data[\"Book-Rating\"].values\n","})\n","# 데이터셋 분할 비율 설정\n","train_size = int(len(train_data) * 0.8)\n","test_size = len(train_data) - train_size\n","\n","# 훈련 및 테스트 세트로 분할\n","train = ratings.take(train_size)\n","test = ratings.skip(train_size)\n","\n","# 도서 제목과 사용자 ID 추출\n","unique_user_ids = np.unique(train_data[\"User-ID\"].values)\n","unique_book_titles = np.unique(train_data[\"Book-Title\"].values)\n","\n","# 정보 출력\n","print(\"First 10 unique book titles:\", list(unique_book_titles)[:10])\n","print(\"Number of unique book titles:\", len(unique_book_titles))\n","print(\"Number of unique user ids:\", len(unique_user_ids))"]},{"cell_type":"markdown","metadata":{},"source":["## TFRS - RetrievalModel"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":423,"status":"ok","timestamp":1709820532964,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"XLuCtX2AcpmT"},"outputs":[],"source":["class RetrievalModel(tf.keras.Model):\n","  def __init__(self):\n","    super().__init__()\n","    embedding_dimension = 32 # 임베딩 벡터 차원\n","    # 순차적으로 쌓기 위해(문자열-> 정수인덱스)\n","    self.user_model = tf.keras.Sequential([\n","      tf.keras.layers.StringLookup(\n","          vocabulary=unique_user_ids, mask_token=None), # 모든 토큰 처리\n","      \n","      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension) # 추가적인 임베딩 생성\n","    ])\n","\n","    self.book_model = tf.keras.Sequential([\n","      tf.keras.layers.StringLookup(\n","          vocabulary=unique_book_titles, mask_token=None),\n","      tf.keras.layers.Embedding(len(unique_book_titles) + 1, embedding_dimension)\n","    ])"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":363,"status":"ok","timestamp":1709820544256,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"mehx7daYcpjy"},"outputs":[],"source":["# 추천 책에 대한 임베딩 생성을 위한 데이터 셋 준비\n","class BookRetrievalModel(tfrs.Model):\n","\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.retrieval_model = RetrievalModel() #북 추천 모델\n","    self.task = tfrs.tasks.Retrieval(\n","      metrics = tfrs.metrics.FactorizedTopK(\n","        candidates = tf.data.Dataset.from_tensor_slices(train_data['Book-Title']).batch(128).map(self.retrieval_model.book_model) # 책 제목을 개별적인 텐서로 나눔\n","      )\n","    )\n","  # loss 값 계산\n","  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor: # 학습모드 여부\n","    \n","    user_embeddings = self.retrieval_model.user_model(features[\"user_id\"]) # 사용자 ID에 대한 사용자 임베딩을 추출\n","    positive_book_embeddings = self.retrieval_model.book_model(features[\"book_title\"]) # 책 제목에 대한 사용자 임베딩을 추출\n","\n","    return self.task(user_embeddings, positive_book_embeddings)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":1228,"status":"ok","timestamp":1709820725348,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"rezLIZymcphM"},"outputs":[],"source":["retrieval_model = BookRetrievalModel()\n","retrieval_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":546,"status":"ok","timestamp":1709820727997,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"CXqkmP0xjWGD"},"outputs":[],"source":["cached_train = train.cache()\n","cached_test = test.cache()"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1709820768078,"user":{"displayName":"심현지","userId":"07523778994702481005"},"user_tz":-540},"id":"DEpUHwHUimgP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"name":"stdout","output_type":"stream","text":["     2/697114 [..............................] - ETA: 151:05:43 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.0000e+00 - regularization_loss: 0.0000e+00 - total_loss: 0.0000e+00"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m retrieval_model\u001b[38;5;241m.\u001b[39mfit(cached_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["retrieval_model.fit(cached_train, epochs=3)"]},{"cell_type":"markdown","metadata":{"id":"_lflUevPVs0m"},"source":["## TFRS - Ranking model"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Class Distribution:\n"," Book-Rating\n","0     548804\n","8      76971\n","10     60024\n","7      55852\n","9      50494\n","5      38416\n","6      26670\n","4       6462\n","3       4374\n","2       2019\n","1       1307\n","Name: count, dtype: int64\n","Resampled Class Distribution:\n"," Book-Rating\n","8     548804\n","0     548804\n","5     548804\n","9     548804\n","7     548804\n","6     548804\n","10    548804\n","2     548804\n","3     548804\n","4     548804\n","1     548804\n","Name: count, dtype: int64\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\simhyunji\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:361: UserWarning: `build()` was called on layer 'book_ranking_model_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 57ms/step - loss: 3.0934 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 2.7057 - total_loss: 3.0934 - val_loss: 4.2893 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.4911 - val_total_loss: 4.2893\n","Epoch 2/5\n","\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 53ms/step - loss: 3.1173 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 2.7213 - total_loss: 3.1173 - val_loss: 5.8159 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.7911 - val_total_loss: 5.8159\n","Epoch 3/5\n","\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 54ms/step - loss: 3.9179 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 3.1897 - total_loss: 3.9179 - val_loss: 4.3978 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.5081 - val_total_loss: 4.3978\n","Epoch 4/5\n","\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 54ms/step - loss: 2.9267 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 2.6529 - total_loss: 2.9267 - val_loss: 5.3226 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.6982 - val_total_loss: 5.3226\n","Epoch 5/5\n","\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 54ms/step - loss: 3.7775 - regularization_loss: 0.0000e+00 - root_mean_squared_error: 2.9875 - total_loss: 3.7775 - val_loss: 5.8515 - val_regularization_loss: 0.0000e+00 - val_root_mean_squared_error: 1.8002 - val_total_loss: 5.8515\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from typing import Dict, Text\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import StandardScaler\n","from imblearn.over_sampling import RandomOverSampler\n","import tensorflow_recommenders as tfrs\n","\n","# 데이터 불러오기\n","train1 = pd.read_csv(\"train.csv\")\n","train_data = train1.copy()\n","\n","# 필요한 열만 선택\n","train_data = train_data[[\"User-ID\", \"Book-Rating\", \"Book-Title\"]]\n","\n","# Book-Rating 값에 따른 클래스 분포 확인\n","class_distribution = train_data[\"Book-Rating\"].value_counts()\n","print(\"Class Distribution:\\n\", class_distribution)\n","\n","# 오버샘플링 적용\n","oversampler = RandomOverSampler(random_state=42)\n","X_resampled, y_resampled = oversampler.fit_resample(train_data.drop(columns=[\"Book-Rating\"]), train_data[\"Book-Rating\"])\n","\n","# 샘플링 결과 확인\n","print(\"Resampled Class Distribution:\\n\", pd.Series(y_resampled).value_counts())\n","\n","# 사용자 ID와 책 제목에 StringLookup 레이어 적용\n","user_ids_vocabulary = np.unique(X_resampled[\"User-ID\"])\n","book_titles_vocabulary = np.unique(X_resampled[\"Book-Title\"])\n","\n","user_ids_lookup = tf.keras.layers.StringLookup(vocabulary=user_ids_vocabulary, mask_token=None)\n","book_titles_lookup = tf.keras.layers.StringLookup(vocabulary=book_titles_vocabulary, mask_token=None)\n","\n","# TensorFlow 데이터셋으로 변환\n","ratings = tf.data.Dataset.from_tensor_slices({\n","        \"user_id\": user_ids_lookup(X_resampled[\"User-ID\"]),\n","        \"book_title\": book_titles_lookup(X_resampled[\"Book-Title\"]),\n","        \"book_rating\": y_resampled\n","})\n","\n","# 데이터셋 분할 비율 설정\n","train_size = int(len(X_resampled) * 0.8)\n","test_size = len(X_resampled) - train_size\n","\n","# 훈련 및 테스트 세트로 분할\n","train = ratings.take(train_size)\n","test = ratings.skip(train_size)\n","\n","# RankingModel 정의\n","class RankingModel(tf.keras.Model):\n","    def __init__(self, user_embedding_dimension=64, book_embedding_dimension=64):\n","        super().__init__()\n","        \n","        self.user_embeddings = tf.keras.Sequential([\n","            tf.keras.layers.Embedding(len(user_ids_vocabulary) + 1, user_embedding_dimension)\n","        ])\n","        \n","        self.book_embeddings = tf.keras.Sequential([\n","            tf.keras.layers.Embedding(len(book_titles_vocabulary) + 1, book_embedding_dimension)\n","        ])\n","\n","        # predictions\n","        self.ratings = tf.keras.Sequential([\n","            # Learn multiple dense layers.\n","            tf.keras.layers.Dense(256, activation=\"relu\"),\n","            tf.keras.layers.Dense(64, activation=\"relu\"),\n","            # Make rating predictions in the final layer.\n","            tf.keras.layers.Dense(1)\n","        ])\n","\n","    def call(self, inputs):\n","        user_id, book_title = inputs\n","\n","        user_embedding = self.user_embeddings(user_id)\n","        book_embedding = self.book_embeddings(book_title)\n","\n","        return self.ratings(tf.concat([user_embedding, book_embedding], axis=1)) # 최종 평점 예측\n","\n","# BookRankingModel 정의\n","class BookRankingModel(tfrs.models.Model):\n","    def __init__(self, user_embedding_dimension=64, book_embedding_dimension=64):\n","        super().__init__()\n","        self.ranking_model = RankingModel(user_embedding_dimension, book_embedding_dimension)\n","        self.task = tfrs.tasks.Ranking(\n","            loss=tf.keras.losses.MeanSquaredError(), \n","            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n","        )\n","\n","    def call(self, features):\n","        return self.ranking_model(\n","            (features[\"user_id\"], features[\"book_title\"])\n","        )\n","\n","    def compute_loss(self, features, training=False):\n","        labels = features[\"book_rating\"]\n","        rating_predictions = self(features)\n","        return self.task(labels=labels, predictions=rating_predictions)\n","\n","# BookRankingModel 클래스 초기화\n","ranking_model = BookRankingModel()\n","ranking_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n","\n","cached_train = train.batch(4096).cache()\n","cached_test = test.batch(4096).cache()\n","\n","# 모델 훈련\n","history = ranking_model.fit(cached_train, epochs=5, validation_data=cached_test)\n","\n","# 손실 값 확인\n","train_loss = history.history['loss']\n","val_loss = history.history['val_loss']\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m  1/295\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n","         predict_rating  actual_ranking\n","0              7.999862               8\n","1              8.407794               8\n","2              7.977655               8\n","3              8.222039               8\n","4              8.007927               8\n","...                 ...             ...\n","1207364        8.037879              10\n","1207365        8.767473              10\n","1207366        8.032455              10\n","1207367        6.193080              10\n","1207368        7.496315              10\n","\n","[1207369 rows x 2 columns]\n"]}],"source":["# 테스트 데이터셋에서 예측 평점 및 실제 평점 가져오기\n","predicted_ratings = ranking_model.predict(cached_test).flatten()\n","actual_ratings = np.concatenate([sample[\"book_rating\"].numpy() for sample in cached_test])\n","\n","# 데이터프레임 생성\n","result = pd.DataFrame({'predict_rating': predicted_ratings, 'actual_ranking': actual_ratings})\n","\n","# 결과 출력\n","print(result)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["사용자 USER_00000를 위한 상위 5개 권장 제품: \n","The Pulse of Enterprise: Timeframe Ad 1800-1850 (Time Frame)\n","Woman Without A Name (Harlequin Intimate Moments, No 751)\n","And the Coyotes Howled: Family Adventures in Pleasant Valley\n","The Seven Years in Tibet: Screenplay and Story Behind the Film (Newmarket Pictorial Moviebook)\n","Mornings A Seven (Harlequin Desire, No 659)\n"]}],"source":["# 테스트 데이터셋에서 상위 5개 도서를 평가하는 코드\n","user_rand_index = np.where(unique_user_ids == 'USER_00000')[0][0]\n","test_ratings = {}\n","\n","for sample in test.take(5):\n","    user_id = tf.convert_to_tensor([sample['user_id'].numpy()])\n","    book_title = tf.convert_to_tensor([sample['book_title'].numpy()])\n","    rating_predictions = ranking_model({\n","        'user_id': user_id,\n","        'book_title': book_title\n","    })\n","    \n","    book_title_str = unique_book_titles[sample[\"book_title\"].numpy()]  # 실제 책 제목 추출\n","    test_ratings[book_title_str] = rating_predictions.numpy().flatten()[0]\n","\n","print(\"사용자 {}를 위한 상위 5개 권장 제품: \".format(unique_user_ids[user_rand_index]))\n","for title in sorted(test_ratings, key=test_ratings.get, reverse=True):\n","    print(title)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>User-ID</th>\n","      <th>Book-ID</th>\n","      <th>Book-Rating</th>\n","      <th>Age</th>\n","      <th>Location</th>\n","      <th>Book-Title</th>\n","      <th>Book-Author</th>\n","      <th>Year-Of-Publication</th>\n","      <th>Publisher</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_000000</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_044368</td>\n","      <td>8</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Road Taken</td>\n","      <td>Rona Jaffe</td>\n","      <td>2001.0</td>\n","      <td>Mira</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_000001</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_081205</td>\n","      <td>8</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Macbeth (New Penguin Shakespeare)</td>\n","      <td>William Shakespeare</td>\n","      <td>1981.0</td>\n","      <td>Penguin Books</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_000002</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_086781</td>\n","      <td>0</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Waverley (Penguin English Library)</td>\n","      <td>Walter Scott</td>\n","      <td>1981.0</td>\n","      <td>Penguin Books</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_000003</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_098622</td>\n","      <td>0</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Mother Earth Father Sky</td>\n","      <td>Sue Harrison</td>\n","      <td>1991.0</td>\n","      <td>Avon</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_000004</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_180810</td>\n","      <td>8</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>She Who Remembers</td>\n","      <td>Linda Lay Shuler</td>\n","      <td>1989.0</td>\n","      <td>Signet Book</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>TRAIN_000005</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_206799</td>\n","      <td>5</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Neuromancer (Remembering Tomorrow)</td>\n","      <td>William Gibson</td>\n","      <td>1995.0</td>\n","      <td>Ace Books</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>TRAIN_000006</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_239414</td>\n","      <td>9</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>The Little Prince</td>\n","      <td>Antoine de Saint-ExupÃ©ry</td>\n","      <td>1982.0</td>\n","      <td>Harvest Books</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>TRAIN_000007</td>\n","      <td>USER_00000</td>\n","      <td>BOOK_269070</td>\n","      <td>0</td>\n","      <td>23.0</td>\n","      <td>sackville, new brunswick, canada</td>\n","      <td>Forests of the Heart (Newford)</td>\n","      <td>Charles de Lint</td>\n","      <td>2001.0</td>\n","      <td>Tor Books</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             ID     User-ID      Book-ID  Book-Rating   Age  \\\n","0  TRAIN_000000  USER_00000  BOOK_044368            8  23.0   \n","1  TRAIN_000001  USER_00000  BOOK_081205            8  23.0   \n","2  TRAIN_000002  USER_00000  BOOK_086781            0  23.0   \n","3  TRAIN_000003  USER_00000  BOOK_098622            0  23.0   \n","4  TRAIN_000004  USER_00000  BOOK_180810            8  23.0   \n","5  TRAIN_000005  USER_00000  BOOK_206799            5  23.0   \n","6  TRAIN_000006  USER_00000  BOOK_239414            9  23.0   \n","7  TRAIN_000007  USER_00000  BOOK_269070            0  23.0   \n","\n","                           Location                          Book-Title  \\\n","0  sackville, new brunswick, canada                          Road Taken   \n","1  sackville, new brunswick, canada   Macbeth (New Penguin Shakespeare)   \n","2  sackville, new brunswick, canada  Waverley (Penguin English Library)   \n","3  sackville, new brunswick, canada             Mother Earth Father Sky   \n","4  sackville, new brunswick, canada                   She Who Remembers   \n","5  sackville, new brunswick, canada  Neuromancer (Remembering Tomorrow)   \n","6  sackville, new brunswick, canada                   The Little Prince   \n","7  sackville, new brunswick, canada      Forests of the Heart (Newford)   \n","\n","                 Book-Author  Year-Of-Publication      Publisher  \n","0                 Rona Jaffe               2001.0           Mira  \n","1        William Shakespeare               1981.0  Penguin Books  \n","2               Walter Scott               1981.0  Penguin Books  \n","3               Sue Harrison               1991.0           Avon  \n","4           Linda Lay Shuler               1989.0    Signet Book  \n","5             William Gibson               1995.0      Ace Books  \n","6  Antoine de Saint-ExupÃ©ry               1982.0  Harvest Books  \n","7            Charles de Lint               2001.0      Tor Books  "]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["train1[train1['User-ID'] == 'USER_00000']"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
